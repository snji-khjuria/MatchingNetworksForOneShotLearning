{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#essential imports\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_location    = \"../dataset/images_background\"\n",
    "evaluate_location = \"../dataset/images_evaluation\"\n",
    "#dataset:- class->char1,2,3,...->*.png\n",
    "def read_omniglot():\n",
    "    data = []\n",
    "    for r in [train_location, evaluate_location]:\n",
    "        classes = glob.glob(r + \"/*\")\n",
    "        #for each of the name of class\n",
    "        for cls in tqdm(classes):\n",
    "            #get the directory for each of the alphabet\n",
    "            alphabets = glob.glob(cls + \"/*\")\n",
    "            for a in alphabets:\n",
    "                #get each file name\n",
    "                characters = glob.glob(a+\"/*\")\n",
    "                raws = []\n",
    "                for ch in characters:\n",
    "                    raw = scipy.misc.imread(ch)\n",
    "                    raw = scipy.misc.imresize(raw, (28, 28))\n",
    "                    #for data augmentation\n",
    "                    for dg in [0, 90, 180, 270]:\n",
    "                        raw_rot = scipy.misc.imrotate(raw, dg)\n",
    "                        raw_rot = raw_rot[:, :, np.newaxis]\n",
    "                        raw_rot = raw_rot.astype(np.float32) / 255\n",
    "                        raws.append(raw_rot)\n",
    "                #raws shape:- (80, 28, 28, 1)\n",
    "                data.append(np.asarray(raws))\n",
    "#                 print(\"Raws shape \" + str(np.asarray(raws).shape))\n",
    "    #data shape is (1623, 80, 28, 28, 1)\n",
    "    np.save(\"omniglot.npy\", np.asarray(data))\n",
    "#     print(\"SHape of data \" + str(np.asarray(data).shape))\n",
    "# read_omniglot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#build the dataloader class\n",
    "class Data_loader():\n",
    "    def __init__(self, batch_size, n_way=5, k_shot=1, train_mode=True):\n",
    "        if not os.path.exists('omniglot.npy'):\n",
    "            read_omniglot()\n",
    "        self.batch_size = batch_size\n",
    "        #number of classes model look at\n",
    "        self.n_way      = n_way\n",
    "        #k shot means k examples for each class\n",
    "        self.k_shot     = k_shot\n",
    "        omniglot        = np.load('omniglot.npy')\n",
    "        np.random.shuffle(omniglot)\n",
    "        #well max of omniglot is 1.0 and min is 0.0\n",
    "        print(\"shape of omniglot is \" + str(omniglot.shape))\n",
    "        if train_mode:\n",
    "            self.images = omniglot[:1200, :20, :, :, :]\n",
    "            self.num_classes = self.images.shape[0]\n",
    "            self.num_samples = self.images.shape[1]\n",
    "        else:\n",
    "            self.images = omniglot[1200:, :20, :, :, :]\n",
    "            self.num_classes = self.images.shape[0]\n",
    "            self.num_samples = self.images.shape[1]\n",
    "        #number of iterations = number of classes so far\n",
    "        self.iters = self.num_classes\n",
    "        \n",
    "    def next_batch(self):\n",
    "        x_set_batch = []\n",
    "        y_set_batch = []\n",
    "        x_hat_batch = []\n",
    "        y_hat_batch = []\n",
    "        #build each set and xhat, yhat\n",
    "        #set means k examples of n way implies n*k\n",
    "        for _ in xrange(self.batch_size):\n",
    "            x_set = []\n",
    "            y_set = []\n",
    "            x     = []\n",
    "            y     = []\n",
    "            #get n classes randomly\n",
    "            classes = np.random.permutation(self.num_classes)[:self.n_way]\n",
    "            #get random target class\n",
    "            target_class = np.random.randint(self.n_way)\n",
    "            for i, c in enumerate(classes):\n",
    "                #get particular samples of the class\n",
    "                samples = np.random.permutation(self.num_samples)[:self.k_shot+1]\n",
    "                for s in samples[:-1]:\n",
    "                    x_set.append(self.images[c][s])\n",
    "                    y_set.append(i)\n",
    "                \n",
    "                if i==target_class:\n",
    "                    x_hat_batch.append(self.images[c][samples[-1]])\n",
    "                    y_hat_batch.append(i)\n",
    "                    \n",
    "            x_set_batch.append(x_set)\n",
    "            y_set_batch.append(y_set)\n",
    "        return np.asarray(x_set_batch).astype(np.float32), np.asarray(y_set_batch).astype(np.int32), np.asarray(x_hat_batch).astype(np.float32), np.asarray(y_hat_batch).astype(np.int32)\n",
    "#         return np.asarray(x_set_batch).astype(np.float32), np.asarray(y_set_batch).astype(np.int32), np.asarray(x_hat_batch).astype(np.float32), np.asarray(y_hat_batch).asarray(np.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim\n",
    "rnn  = tf.contrib.rnn\n",
    "class Matching_Nets():\n",
    "    #get the model hyperparameters and create placeholders\n",
    "    def __init__(self,  lr, n_way, k_shot, use_fce, batch_size=32):\n",
    "        self.lr                   = lr\n",
    "        self.n_way                = n_way\n",
    "        self.k_shot               = k_shot\n",
    "        self.use_fce              = use_fce\n",
    "        self.batch_size           = batch_size\n",
    "        self.processing_steps     = 10\n",
    "        self.support_set_image_ph = tf.placeholder(tf.float32, [None, n_way*k_shot, 28, 28, 1])\n",
    "        self.support_set_label_ph = tf.placeholder(tf.int32, [None, n_way*k_shot])\n",
    "        self.example_image_ph     = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "        self.example_label_ph     = tf.placeholder(tf.int32, [None, ])\n",
    "    \n",
    "    def image_encoder(self, image):\n",
    "        #create 4 layer image net\n",
    "        with slim.arg_scope([slim.conv2d], num_outputs=64, kernel_size=3, normalizer_fn=slim.batch_norm):\n",
    "            net = slim.conv2d(image)\n",
    "            net = slim.max_pool2d(net, [2, 2])\n",
    "            net = slim.conv2d(net)\n",
    "            net = slim.max_pool2d(net, [2, 2])\n",
    "            net = slim.conv2d(net)\n",
    "            net = slim.max_pool2d(net, [2, 2])\n",
    "            net = slim.conv2d(net)\n",
    "            net = slim.max_pool2d(net, [2, 2])\n",
    "        return tf.reshape(net, [-1, 1 * 1 * 64])\n",
    "    \n",
    "    #cosine similarity for embedded support set and target\n",
    "    def cosine_similarity(self, target, support_set):\n",
    "        target_normed = target\n",
    "        sup_similarity = []\n",
    "        for i in tf.unstack(support_set):\n",
    "            #batch X 64\n",
    "            i_normed = tf.nn.l2_normalize(i, 1)\n",
    "            #(batch, )\n",
    "            similarity = tf.matmul(tf.expand_dims(target_normed, 1), tf.expand_dims(i_normed, 2))\n",
    "            sup_similarity.append(similarity)\n",
    "        #batch, n*k\n",
    "        return tf.squeeze(tf.stack(sup_similarity, axis=1))\n",
    "    \n",
    "    \n",
    "    def build(self, support_set_image, support_set_label, image):\n",
    "        #batch X 64\n",
    "        image_encoded             = self.image_encoder(image)\n",
    "        support_set_image_encoded = [self.image_encoder(i) for i in tf.unstack(support_set_image, axis=1)]\n",
    "        #batch x 64\n",
    "        f_embedding               = image_encoded\n",
    "        #n*k, batch, 64\n",
    "        g_embedding               = tf.stack(support_set_image_encoded)\n",
    "        #c(f(xhat), g(xi))\n",
    "        #batch, n*k\n",
    "        embedding_similarity      = self.cosine_similarity(f_embedding, g_embedding)\n",
    "        #compute softmax on similarity to get a(xhat, xi)\n",
    "        attention                 = tf.nn.softmax(embedding_similarity)\n",
    "        y_hat                     = tf.matmul(tf.expand_dims(attention, 1), tf.one_hot(support_set_label, self.n_way))\n",
    "        self.logits               = tf.squeeze(y_hat)\n",
    "        self.pred                 = tf.argmax(self.logits, 1)\n",
    "        \n",
    "    def loss(self, label):\n",
    "        self.loss_op = tf.losses.sparse_softmax_cross_entropy(label, self.logits)\n",
    "        \n",
    "    def train(self):\n",
    "        return tf.train.AdamOptimizer(self.lr).minimize(self.loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#hyperparameters:\n",
    "lr     = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "n_way = 20\n",
    "k_shot = 1\n",
    "use_fce = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of omniglot is (1623, 80, 28, 28, 1)\n",
      "shape of omniglot is (1623, 80, 28, 28, 1)\n",
      "Start Training \n",
      "batch size 32, epoch: 100, initial lr: 0.001\n",
      "(32, 20, 28, 28, 1)\n",
      "(32, 20)\n",
      "(32, 28, 28, 1)\n",
      "(32,)\n",
      "(20, 32, 1, 1)\n",
      "(32, 1, 1)\n",
      "(32, 20)\n",
      "(32, 1, 20)\n",
      "One hot (32, 20, 20)\n",
      "encoded points is (32, 64)\n",
      "epoints are (20, 32, 64)\n",
      "epoints2 are (20, 32, 64)\n",
      "Model similarity is (32, 20)\n",
      "epoch   1, step   0, loss   2, acc 3.12%\n",
      "(32, 20, 28, 28, 1)\n",
      "(32, 20)\n",
      "(32, 28, 28, 1)\n",
      "(32,)\n",
      "(20, 32, 1, 1)\n",
      "(32, 1, 1)\n",
      "(32, 20)\n",
      "(32, 1, 20)\n",
      "One hot (32, 20, 20)\n",
      "encoded points is (32, 64)\n",
      "epoints are (20, 32, 64)\n",
      "epoints2 are (20, 32, 64)\n",
      "Model similarity is (32, 20)\n",
      "(32, 20, 28, 28, 1)\n",
      "(32, 20)\n",
      "(32, 28, 28, 1)\n",
      "(32,)\n",
      "(20, 32, 1, 1)\n",
      "(32, 1, 1)\n",
      "(32, 20)\n",
      "(32, 1, 20)\n",
      "One hot (32, 20, 20)\n",
      "encoded points is (32, 64)\n",
      "epoints are (20, 32, 64)\n",
      "epoints2 are (20, 32, 64)\n",
      "Model similarity is (32, 20)\n",
      "(32, 20, 28, 28, 1)\n",
      "(32, 20)\n",
      "(32, 28, 28, 1)\n",
      "(32,)\n",
      "(20, 32, 1, 1)\n",
      "(32, 1, 1)\n",
      "(32, 20)\n",
      "(32, 1, 20)\n",
      "One hot (32, 20, 20)\n",
      "encoded points is (32, 64)\n",
      "epoints are (20, 32, 64)\n",
      "epoints2 are (20, 32, 64)\n",
      "Model similarity is (32, 20)\n",
      "(32, 20, 28, 28, 1)\n",
      "(32, 20)\n",
      "(32, 28, 28, 1)\n",
      "(32,)\n",
      "(20, 32, 1, 1)\n",
      "(32, 1, 1)\n",
      "(32, 20)\n",
      "(32, 1, 20)\n",
      "One hot (32, 20, 20)\n",
      "encoded points is (32, 64)\n",
      "epoints are (20, 32, 64)\n",
      "epoints2 are (20, 32, 64)\n",
      "Model similarity is (32, 20)\n",
      "(32, 20, 28, 28, 1)\n",
      "(32, 20)\n",
      "(32, 28, 28, 1)\n",
      "(32,)\n",
      "(20, 32, 1, 1)\n",
      "(32, 1, 1)\n",
      "(32, 20)\n",
      "(32, 1, 20)\n",
      "One hot (32, 20, 20)\n",
      "encoded points is (32, 64)\n",
      "epoints are (20, 32, 64)\n",
      "epoints2 are (20, 32, 64)\n",
      "Model similarity is (32, 20)\n",
      "(32, 20, 28, 28, 1)\n",
      "(32, 20)\n",
      "(32, 28, 28, 1)\n",
      "(32,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-535c8f15d546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-535c8f15d546>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mepoints2\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoints2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0ms\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0msimilarity2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0msim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0ms3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maulik/environments/matchnet_env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maulik/environments/matchnet_env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maulik/environments/matchnet_env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maulik/environments/matchnet_env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maulik/environments/matchnet_env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maulik/environments/matchnet_env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#main model function calling\n",
    "def train():\n",
    "    train_loader = Data_loader(batch_size, n_way, k_shot)\n",
    "    eval_loader  = Data_loader(batch_size, n_way, k_shot, train_mode=False)\n",
    "    model = Matching_Nets(lr, n_way, k_shot, use_fce, batch_size)\n",
    "    model.build(model.support_set_image_ph, model.support_set_label_ph, model.example_image_ph)\n",
    "    model.loss(model.example_label_ph)\n",
    "    train_op = model.train()\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Start Training ')\n",
    "    print('batch size %d, epoch: %d, initial lr: %.3f' %(batch_size, epochs, lr))\n",
    "    for epoch in xrange(epochs):\n",
    "        correct = []\n",
    "        for step in xrange(train_loader.iters):\n",
    "            x_set, y_set, x_hat, y_hat = train_loader.next_batch()\n",
    "            feed_dict = {model.support_set_image_ph:x_set,\n",
    "                        model.support_set_label_ph:y_set,\n",
    "                        model.example_image_ph:x_hat,\n",
    "                        model.example_label_ph:y_hat}\n",
    "            logits, predictions, loss, _ = sess.run([model.logits, model.pred, model.loss_op, train_op], feed_dict=feed_dict)\n",
    "            correct.append(np.equal(predictions, y_hat))\n",
    "            if step%100==0:\n",
    "                print(\"epoch %3d, step %3d, loss %3d, acc %.2f%%\" % (epoch+1, step, loss, np.mean(np.equal(predictions, y_hat))*100))\n",
    "                \n",
    "        print('Training accuracy: %.2f%%'%(np.mean(np.stack(correct)) * 100))\n",
    "        correct = []\n",
    "        for step in xrange(eval_loader.iters):\n",
    "            x_set, y_set, x_hat, y_hat = eval_loader.next_batch()\n",
    "            feed_dict = {model.support_set_image_ph:x_set,\n",
    "                        model.support_set_label_ph:y_set,\n",
    "                        model.example.image_ph:x_hat}\n",
    "            logits, prediction = sess.run([model.logits, model.pred], feed_dict=feed_dict)\n",
    "            correct.append(np.equal(prediction, y_hat))\n",
    "        print('Evaluation accuracy: %.2f%%' % (np.mean(np.stack(correct)) * 100))\n",
    "    print('Done')\n",
    "    \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "        if self.use_fce:\n",
    "            g_embedding = self.fce_g(support_set_image_encoded)     # (n * k, batch_size, 64)\n",
    "            f_embedding = self.fce_f(image_encoded, g_embedding)    # (batch_size, 64)\n",
    "\n",
    "\n",
    "#encoded xi:- [batch, 64] of size n*k\n",
    "#output:- [n*k, batch, 64] where lstm cell needs [batch, 64] for that length of n*k classes.\n",
    "def fce_g(self, encoded_x_i):\n",
    "        \"\"\"the fully conditional embedding function g\n",
    "        This is a bi-directional LSTM, g(x_i, S) = h_i(->) + h_i(<-) + g'(x_i) where g' is the image encoder\n",
    "        For omniglot, this is not used.\n",
    "\n",
    "        encoded_x_i: g'(x_i) in the equation.   length n * k list of (batch_size ,64)\n",
    "        \"\"\"\n",
    "        fw_cell = rnn.BasicLSTMCell(32) # 32 is half of 64 (output from cnn)\n",
    "        bw_cell = rnn.BasicLSTMCell(32)\n",
    "        outputs, state_fw, state_bw = rnn.static_bidirectional_rnn(fw_cell, bw_cell, encoded_x_i, dtype=tf.float32)\n",
    "\n",
    "        return tf.add(tf.stack(encoded_x_i), tf.stack(outputs))\n",
    "\n",
    "    def fce_f(self, encoded_x, g_embedding):\n",
    "        \"\"\"the fully conditional embedding function f\n",
    "        This is just a vanilla LSTM with attention where the input at each time step is constant and the hidden state\n",
    "        is a function of previous hidden state but also a concatenated readout vector.\n",
    "        For omniglot, this is not used.\n",
    "\n",
    "        encoded_x: f'(x_hat) in equation (3) in paper appendix A.1.     (batch_size, 64)\n",
    "        g_embedding: g(x_i) in equation (5), (6) in paper appendix A.1. (n * k, batch_size, 64)\n",
    "        \"\"\"\n",
    "        cell = rnn.BasicLSTMCell(64)\n",
    "        prev_state = cell.zero_state(self.batch_size, tf.float32) # state[0] is c, state[1] is h\n",
    "\n",
    "        for step in xrange(self.processing_steps):\n",
    "            output, state = cell(encoded_x, prev_state) # output: (batch_size, 64)\n",
    "            \n",
    "            h_k = tf.add(output, encoded_x) # (batch_size, 64)\n",
    "\n",
    "            content_based_attention = tf.nn.softmax(tf.multiply(prev_state[1], g_embedding))    # (n * k, batch_size, 64)\n",
    "            r_k = tf.reduce_sum(tf.multiply(content_based_attention, g_embedding), axis=0)      # (batch_size, 64)\n",
    "\n",
    "            prev_state = rnn.LSTMStateTuple(state[0], tf.add(h_k, r_k))\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchnet_env",
   "language": "python",
   "name": "matchnet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
